# Configura√ß√£o Multi-GPU

## Vis√£o Geral

O DetectoRR agora suporta distribui√ß√£o autom√°tica de c√¢meras entre m√∫ltiplas GPUs usando estrat√©gia **round-robin**. Esta funcionalidade permite escalar horizontalmente o processamento para ambientes com dezenas de c√¢meras.

## Como Funciona

### Distribui√ß√£o Round-Robin

Cada c√¢mera √© atribu√≠da sequencialmente a uma GPU da lista configurada:

- **C√¢mera 1** ‚Üí GPU 0
- **C√¢mera 2** ‚Üí GPU 1  
- **C√¢mera 3** ‚Üí GPU 2
- **C√¢mera 4** ‚Üí GPU 3
- **C√¢mera 5** ‚Üí GPU 0 (ciclo reinicia)
- **C√¢mera 6** ‚Üí GPU 1
- ...e assim por diante

### Vantagens

‚úÖ **Simples**: Configura√ß√£o direta via arquivo YAML  
‚úÖ **Autom√°tico**: Distribui√ß√£o feita automaticamente pelo sistema  
‚úÖ **Balanceado**: Carga uniforme entre GPUs (¬± 1 c√¢mera de diferen√ßa)  
‚úÖ **Escal√°vel**: Adicione mais GPUs conforme necess√°rio  
‚úÖ **Sem overhead**: Nenhuma sincroniza√ß√£o inter-GPU necess√°ria

## Configura√ß√£o

### 1. Arquivo `config.yaml`

```yaml
# Lista de GPUs a serem utilizadas (distribui√ß√£o round-robin entre c√¢meras)
# Exemplos: 
#   [0]          - usa apenas GPU 0
#   [0, 1]       - usa GPU 0 e 1
#   [0, 1, 2, 3] - usa 4 GPUs
gpu_devices: [0, 1, 2, 3]
```

### 2. Verificar GPUs Dispon√≠veis

Execute no terminal:

```bash
nvidia-smi --list-gpus
```

Exemplo de sa√≠da:
```
GPU 0: NVIDIA RTX A4000 (UUID: GPU-xxx)
GPU 1: NVIDIA RTX A4000 (UUID: GPU-yyy)
GPU 2: NVIDIA RTX A4000 (UUID: GPU-zzz)
GPU 3: NVIDIA RTX A4000 (UUID: GPU-www)
```

### 3. Logs da Aplica√ß√£o

Ao iniciar, voc√™ ver√° logs indicando a distribui√ß√£o:

```
INFO - Distribuindo 20 c√¢mera(s) entre 4 GPU(s): [0, 1, 2, 3]
INFO - [1/20] C√¢mera CAM_ENTRADA ‚Üí GPU 0
INFO - [1/20] GPU 0 selecionada para c√¢mera CAM_ENTRADA
INFO - [2/20] C√¢mera CAM_SAIDA ‚Üí GPU 1
INFO - [2/20] GPU 1 selecionada para c√¢mera CAM_SAIDA
...
```

## Exemplos de Cen√°rios

### Cen√°rio 1: 20 C√¢meras, 1 GPU

```yaml
gpu_devices: [0]
```

**Carga por GPU**: 20 c√¢meras √ó 30 FPS = 600 frames/s  
**Status**: ‚ö†Ô∏è **Sobrecarga** (RTX A4000 processa ~50 frames/s)

### Cen√°rio 2: 20 C√¢meras, 2 GPUs

```yaml
gpu_devices: [0, 1]
```

**Carga por GPU**: 10 c√¢meras √ó 30 FPS = 300 frames/s  
**Status**: ‚ö†Ô∏è **Ainda sobrecarregado** (6√ó capacidade)

### Cen√°rio 3: 20 C√¢meras, 4 GPUs ‚úÖ (RECOMENDADO)

```yaml
gpu_devices: [0, 1, 2, 3]

performance:
  detection_skip_frames: 2  # Processa 1 a cada 2 frames
```

**Carga por GPU**: 5 c√¢meras √ó 15 FPS efetivos = 75 frames/s  
**Status**: ‚úÖ **Balanceado** (1.5√ó capacidade, mas gerenci√°vel)

### Cen√°rio 4: 40 C√¢meras, 4 GPUs

```yaml
gpu_devices: [0, 1, 2, 3]

performance:
  detection_skip_frames: 3  # Processa 1 a cada 3 frames
```

**Carga por GPU**: 10 c√¢meras √ó 10 FPS efetivos = 100 frames/s  
**Status**: ‚ö†Ô∏è **Pr√≥ximo ao limite** (2√ó capacidade)

## C√°lculo de Capacidade

### Capacidade por GPU (RTX A4000 com TensorRT)

- **Modelo YOLO + TensorRT FP16**: ~50-66 frames/s
- **Resolu√ß√£o reduzida (inference_size: 640)**: +20-30% performance
- **Frame skipping (detection_skip_frames: 2)**: Divide carga por 2

### F√≥rmula de Carga

```
Carga por GPU = (N√∫mero de c√¢meras √∑ N√∫mero de GPUs) √ó (FPS √∑ detection_skip_frames)
```

**Exemplo com 20 c√¢meras, 4 GPUs, skip=2:**
```
Carga = (20 √∑ 4) √ó (30 √∑ 2) = 5 √ó 15 = 75 frames/s por GPU
```

## Par√¢metros Relacionados

Combine multi-GPU com outros par√¢metros de performance para m√°xima efici√™ncia:

```yaml
gpu_devices: [0, 1, 2, 3]

performance:
  # Reduz resolu√ß√£o de infer√™ncia (2-4√ó mais r√°pido)
  inference_size: 640
  
  # Processa 1 a cada N frames (reduz carga proporcionalmente)
  detection_skip_frames: 2
  
tensorrt:
  enabled: true
  precision: FP16  # Essencial para performance
  workspace: 4
```

## Monitoramento

### Durante Execu√ß√£o

Monitore uso das GPUs em tempo real:

```bash
watch -n 1 nvidia-smi
```

Voc√™ ver√° algo assim:

```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA 12.2  |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  NVIDIA RTX A4000    On   | 00000000:01:00.0 Off |                  Off |
| 41%   62C    P2   128W / 140W |  12456MiB / 16376MiB |     85%      Default |
|   1  NVIDIA RTX A4000    On   | 00000000:02:00.0 Off |                  Off |
| 43%   64C    P2   132W / 140W |  12678MiB / 16376MiB |     88%      Default |
|   2  NVIDIA RTX A4000    On   | 00000000:03:00.0 Off |                  Off |
| 40%   61C    P2   125W / 140W |  12234MiB / 16376MiB |     82%      Default |
|   3  NVIDIA RTX A4000    On   | 00000000:04:00.0 Off |                  Off |
| 42%   63C    P2   129W / 140W |  12543MiB / 16376MiB |     86%      Default |
+-------------------------------+----------------------+----------------------+
```

**Indicadores saud√°veis:**
- ‚úÖ GPU-Util entre 70-90% (balanceado)
- ‚úÖ Memory-Usage < 90% (sem overflow)
- ‚úÖ Temperatura < 80¬∞C (resfriamento adequado)

## Troubleshooting

### Problema: Erro "CUDA out of memory"

**Causa**: Modelo muito grande ou muitas c√¢meras por GPU

**Solu√ß√µes**:
1. Adicione mais GPUs ao `gpu_devices`
2. Aumente `detection_skip_frames` (reduz frames processados)
3. Reduza `inference_size` (modelos menores)
4. Reduza `gpu_batch_size`

### Problema: GPUs desequilibradas

**Causa**: N√∫mero de c√¢meras n√£o √© m√∫ltiplo do n√∫mero de GPUs

**Exemplo**: 21 c√¢meras, 4 GPUs
- GPU 0: 6 c√¢meras
- GPU 1: 5 c√¢meras  
- GPU 2: 5 c√¢meras
- GPU 3: 5 c√¢meras

**Solu√ß√£o**: Isso √© normal e esperado (diferen√ßa m√°xima de 1 c√¢mera)

### Problema: "RuntimeError: cuda runtime error (10)"

**Causa**: ID de GPU inv√°lido em `gpu_devices`

**Solu√ß√£o**: Verifique IDs dispon√≠veis com `nvidia-smi --list-gpus`

### Problema: Uma GPU n√£o est√° sendo usada

**Causa**: Poss√≠veis problemas:
1. GPU desabilitada no sistema
2. Driver NVIDIA n√£o carregado
3. ID incorreto em `gpu_devices`

**Verifica√ß√µes**:
```bash
# Lista GPUs vis√≠veis
nvidia-smi --list-gpus

# Verifica CUDA dispon√≠vel
python -c "import torch; print(torch.cuda.device_count())"
```

## Migra√ß√£o de Configura√ß√£o Antiga

### Antes (gpu_index)

```yaml
gpu_index: 0
```

### Depois (gpu_devices)

```yaml
# Usa apenas GPU 0 (comportamento id√™ntico)
gpu_devices: [0]

# OU usa m√∫ltiplas GPUs
gpu_devices: [0, 1, 2, 3]
```

**Nota**: O sistema ainda suporta `gpu_index` para compatibilidade, mas `gpu_devices` tem prioridade.

## Performance Esperada

### 20 C√¢meras, 4 GPUs, RTX A4000

**Configura√ß√£o**:
```yaml
gpu_devices: [0, 1, 2, 3]
performance:
  inference_size: 640
  detection_skip_frames: 2
  max_parallel_workers: 10
tensorrt:
  enabled: true
  precision: FP16
```

**Resultados Esperados**:
- üìä FPS por c√¢mera: **25-28 FPS**
- ‚è±Ô∏è Lat√™ncia m√©dia: **400-600ms**
- üî• Uso por GPU: **85-90%**
- üíæ VRAM por GPU: **11-13GB**
- üéØ Taxa de detec√ß√£o: **>95%**

## Recomenda√ß√µes

1. **Use TensorRT**: Essencial para performance (~2-3√ó speedup)
2. **Adicione GPUs conforme necess√°rio**: 1 GPU a cada 5-7 c√¢meras
3. **Monitore uso**: `nvidia-smi` deve mostrar 70-90% utiliza√ß√£o
4. **Ajuste skip_frames**: Balance entre FPS e carga
5. **Teste incrementalmente**: Adicione c√¢meras gradualmente

## Suporte

Para d√∫vidas sobre configura√ß√£o multi-GPU, consulte tamb√©m:
- `PERFORMANCE.md` - Guia completo de otimiza√ß√£o
- Logs da aplica√ß√£o em `detectorrbt.log`
- Output de `nvidia-smi` para diagn√≥stico
